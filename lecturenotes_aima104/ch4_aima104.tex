\documentclass[aima104_lecturenotes_ku.tex]{subfiles}

\setcounter{chapter}{3}
\begin{document}
\chapter{Orthogonality and Least Squares}
\section{Inner Product}
Let $u =
\begin{bmatrix}
  u_1 \\ u_2 \\ . \\ .\\ .\\ u_n
\end{bmatrix} $ and $v =
\begin{bmatrix}
  v_1 \\ v_2 \\ . \\ .\\ .\\ v_n
\end{bmatrix} $ be any two vectors in $\mathbb{R}^n$. Then the number $u^T\, v$ is called the \textbf{inner product} of $u$ and $v$. This inner product is also commonly known as \textbf{dot product} and denoted by $\mathbf{u.v}$.

\subsection{Properties of Inner Product}
\begin{mdframed}
  \begin{enumerate}
  \item $u.v = v.u$
  \item $(u+v).w = u.w + v.w$
  \item $(\alpha u).v = \alpha (u.v) = u. (cv)$
  \item $u.u \geq 0$ and $u.u = 0 \Longleftrightarrow u=0$
  \end{enumerate}
\end{mdframed}

\subsection{The Length of a Vector}
The length of a vector $v$ is called the \textbf{norm} of $v$. \\ It is denoted by $\Vert v \Vert$ and defined by $\Vert v \Vert = \sqrt{v_1^2 + v_2^2 + ... + v_n^2} $ so that, $\Vert v \Vert ^2 = v.v$ There are several kinds of norms actually, this particular norm is called \textbf{Euclidean norm}.
For any scalar $\alpha$, $\Vert \alpha v \Vert = \vert \alpha \vert \Vert v \Vert$. A vector whose length is unity is called a \textbf{unit vector}. If we divide a nonzero vector $v$ by its length, we obtain a unit vector $u$. This process is called \textbf{normalizing} of the vector $v$.

\subsubsection{Distance between vectors}
For $u$ and $v$ in a vector space $V$, the distance between them is written as dist(u,v) and is defined as $dist(u,v) = \Vert u-v \Vert$.

\section{Orthogonal Vectors}
The two vectors $u$ and $v$ are orthogonal vectors if their dot product is zero,i.e $u.v = 0$. Observe that the zero vector is orthogonal to every vector as $0^Tv=0$ for all $v$.
\begin{thm}[The Pythagorean Theorem]
  Two vectors $u$ and $v$ are orthogonal if and only if $\Vert u + v \Vert ^2 = \Vert u \Vert ^2 + \Vert v \Vert ^2$.
\end{thm}

\subsection{Orthogonal Complement}
\begin{itemize}
\item If a vector $z$ is orthogonal to every vectors in a subspace $W$ then, $z$ is said to be orthogonal to $W$.

\item The set of all vectors that are orthogonal to $W$ is called the \textbf{orthogonal complement} of $W$. It is denoted by $W^{\perp}$. $W^{\perp} = \{z \, : \forall v \in W \;  z.v=0 \} $
\end{itemize}

\begin{thm}
  \begin{enumerate}
  \item A vector $x$ is in $W^{\perp}$ if and only if $x$ is orthogonal to every vector in a set that is spans $W$.
  \item $W^{\perp}$ is also a subspace.
   \item Row space is orthogonal complement of the Null space for a matrix.
  \end{enumerate}
\end{thm}

\subsection{Orthogonal Sets}
A set of vectors $\{ u_1, ...u_p\}$ in a vector space $V$ is said to be \textbf{orthogonal set} if each pair of distinct vectors from the set is orthogonal,i.e for all $u_i, u_j \in V$ we have $u_i.u_j = 0$ whenever $i \neq j$.

\end{document}


%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: t
%%% End:
